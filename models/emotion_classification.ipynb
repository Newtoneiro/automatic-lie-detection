{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mConnection is disposed. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.optim import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'PyTorch version: {torch.__version__}')\n",
    "print('*'*10)\n",
    "print(f'_CUDA version: ')\n",
    "!nvcc --version\n",
    "print('*'*10)\n",
    "print(f'CUDNN version: {torch.backends.cudnn.version()}')\n",
    "print(f'Available GPU devices: {torch.cuda.device_count()}')\n",
    "print(f'Device Name: {torch.cuda.get_device_name()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zdobycie danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = os.path.abspath(os.path.join('..', 'data', 'processed', 'ravdess'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "LANDMARK_INDEXES = [\n",
    "    76, 306,  # mouth corners\n",
    "    74, 73, 72, 11, 302, 303, 304, # upper lip\n",
    "    90, 180, 85, 16, 315, 404, 320, # lower lip\n",
    "    33, 161, 159, 157, 133, 154, 145, 163,  # left eye\n",
    "    70, 63, 105, 66, 107,  # left eyebrow\n",
    "    362, 384, 386, 388, 263, 390, 374, 381,  # right eye\n",
    "    300, 293, 334, 296, 336,  # right eyebrow\n",
    "    1, 5, 197, 168  # nose\n",
    "]\n",
    "\n",
    "REFERENCE_LANDMARK_INDEX = 0  # Middle of face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_coordinates_to_avg_distance(frames):\n",
    "    out = []\n",
    "    for frame in frames:\n",
    "        frame_distance = 0\n",
    "        for landmark_idx in LANDMARK_INDEXES:\n",
    "            frame_distance += math.sqrt(\n",
    "                (frame[REFERENCE_LANDMARK_INDEX][0] - frame[landmark_idx][0])**2 +\n",
    "                (frame[REFERENCE_LANDMARK_INDEX][1] - frame[landmark_idx][1])**2\n",
    "            )\n",
    "        out.append(frame_distance / len(LANDMARK_INDEXES))\n",
    "    return np.array(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_path):\n",
    "    all_data = []\n",
    "    all_labels = []\n",
    "\n",
    "    for file in os.listdir(data_path):\n",
    "        if file.endswith(\".npy\"):\n",
    "            data = np.load(os.path.join(data_path, file), allow_pickle=True)\n",
    "            data = np.array(data, dtype=np.float32)\n",
    "\n",
    "            all_data.append(data)\n",
    "\n",
    "            label = int(file.split(\"-\")[2])\n",
    "            all_labels.append(label)\n",
    "\n",
    "    return np.array(all_data, dtype=object), np.array(all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data, all_labels = load_data(DATA_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(data, labels):\n",
    "    tensor_data = [torch.tensor(d, dtype=torch.float32) for d in data]\n",
    "    padded_data = pad_sequence(tensor_data, batch_first=True)\n",
    "\n",
    "    encoder = LabelBinarizer()\n",
    "    encoded_labels = encoder.fit_transform(labels)\n",
    "    encoded_labels = torch.tensor(encoded_labels, dtype=torch.float32)\n",
    "\n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "        padded_data, encoded_labels, test_size=0.3, random_state=42\n",
    "    )\n",
    "    X_val, X_test, y_val, y_test = train_test_split(\n",
    "        X_temp, y_temp, test_size=0.5, random_state=42\n",
    "    )\n",
    "\n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, X_test, y_train, y_val, y_test = preprocess_data(all_data, all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class distribution\n",
    "from collections import Counter\n",
    "\n",
    "for key, val in sorted(Counter((label.argmax().item() for label in y_train)).items(), key=lambda i: i[0]):\n",
    "    print(f\"{key}:{val}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### W podejściu wykorzystane zostaną 2 modele - pierwszy z nich będzie siecią konwolucyjną 2d, która będzie miała za zadanie nauczyć się rozpoznawać cechy charakterystyczne dla wybranej klatki (zbioru współrzędnych pkt charakterystycznych). Do klasyfikacji szeregu czasowego zostanie wykorzystana sekwencyjna sieć neuronowa LSTM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zbudowanie modelu ekstrakcji cech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmotionClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EmotionClassifier, self).__init__()\n",
    "        \n",
    "        # Spatial feature extraction using Conv1D\n",
    "        self.conv1 = nn.Conv1d(in_channels=2, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.pool1 = nn.MaxPool1d(kernel_size=2)\n",
    "        \n",
    "        # LSTM layers for temporal feature extraction\n",
    "        self.lstm1 = nn.LSTM(input_size=32 * 239, hidden_size=128, batch_first=True, bidirectional=True)\n",
    "        self.lstm2 = nn.LSTM(input_size=128 * 2, hidden_size=64, batch_first=True)\n",
    "        \n",
    "        # Fully connected classification layer\n",
    "        self.fc = nn.Linear(64, 8)  # 8 emotion classes\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: (batch_size, frames, landmarks, coordinates)\n",
    "        batch_size, frames, landmarks, coordinates = x.shape\n",
    "        \n",
    "        # Reshape for Conv1D: (batch_size * frames, landmarks, coordinates)\n",
    "        x = x.view(-1, landmarks, coordinates).permute(0, 2, 1)\n",
    "        \n",
    "        # Spatial feature extraction\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "        \n",
    "        # Flatten spatial features\n",
    "        x = x.view(batch_size, frames, -1)  # (batch_size, frames, features)\n",
    "        \n",
    "        # Temporal feature extraction\n",
    "        x, _ = self.lstm1(x)\n",
    "        x, _ = self.lstm2(x)\n",
    "        \n",
    "        # Classification\n",
    "        x = self.fc(x[:, -1, :])  # Take the last timestep's output\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = EmotionClassifier().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "EPOCHS = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "val_dataset = TensorDataset(X_val, y_val)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Train Loss: 130.4258, Train Acc: 0.1426, Val Loss: 28.9031, Val Acc: 0.1276\n",
      "Epoch 2/50, Train Loss: 130.0251, Train Acc: 0.1491, Val Loss: 28.8230, Val Acc: 0.1276\n",
      "Epoch 3/50, Train Loss: 129.9188, Train Acc: 0.1595, Val Loss: 28.7528, Val Acc: 0.1624\n",
      "Epoch 4/50, Train Loss: 129.6616, Train Acc: 0.1665, Val Loss: 28.6748, Val Acc: 0.1578\n",
      "Epoch 5/50, Train Loss: 129.0575, Train Acc: 0.1759, Val Loss: 28.5606, Val Acc: 0.1694\n",
      "Epoch 6/50, Train Loss: 128.9573, Train Acc: 0.1750, Val Loss: 28.4839, Val Acc: 0.1694\n",
      "Epoch 7/50, Train Loss: 128.4577, Train Acc: 0.1754, Val Loss: 28.3487, Val Acc: 0.1740\n",
      "Epoch 8/50, Train Loss: 128.0457, Train Acc: 0.1814, Val Loss: 28.1774, Val Acc: 0.1717\n",
      "Epoch 9/50, Train Loss: 127.1643, Train Acc: 0.1953, Val Loss: 27.9658, Val Acc: 0.1810\n",
      "Epoch 10/50, Train Loss: 126.1503, Train Acc: 0.1968, Val Loss: 27.7974, Val Acc: 0.1647\n",
      "Epoch 11/50, Train Loss: 125.5527, Train Acc: 0.1958, Val Loss: 27.6124, Val Acc: 0.1903\n",
      "Epoch 12/50, Train Loss: 124.9684, Train Acc: 0.2087, Val Loss: 27.5381, Val Acc: 0.1972\n",
      "Epoch 13/50, Train Loss: 125.4554, Train Acc: 0.1958, Val Loss: 27.4165, Val Acc: 0.1787\n",
      "Epoch 14/50, Train Loss: 124.6023, Train Acc: 0.2053, Val Loss: 27.3803, Val Acc: 0.1833\n",
      "Epoch 15/50, Train Loss: 124.4628, Train Acc: 0.2023, Val Loss: 27.5315, Val Acc: 0.1949\n",
      "Epoch 16/50, Train Loss: 124.4627, Train Acc: 0.2147, Val Loss: 27.3147, Val Acc: 0.1995\n",
      "Epoch 17/50, Train Loss: 124.2032, Train Acc: 0.2117, Val Loss: 27.3465, Val Acc: 0.1972\n",
      "Epoch 18/50, Train Loss: 123.6696, Train Acc: 0.2127, Val Loss: 27.3534, Val Acc: 0.2042\n",
      "Epoch 19/50, Train Loss: 123.9063, Train Acc: 0.2097, Val Loss: 27.2169, Val Acc: 0.1717\n",
      "Epoch 20/50, Train Loss: 123.8029, Train Acc: 0.1973, Val Loss: 27.2124, Val Acc: 0.1717\n",
      "Epoch 21/50, Train Loss: 123.9958, Train Acc: 0.1973, Val Loss: 27.2200, Val Acc: 0.1903\n",
      "Epoch 22/50, Train Loss: 124.0174, Train Acc: 0.2127, Val Loss: 27.1882, Val Acc: 0.1810\n",
      "Epoch 23/50, Train Loss: 123.6149, Train Acc: 0.2182, Val Loss: 27.1699, Val Acc: 0.1810\n",
      "Epoch 24/50, Train Loss: 123.7333, Train Acc: 0.2068, Val Loss: 27.1688, Val Acc: 0.1717\n",
      "Epoch 25/50, Train Loss: 124.0198, Train Acc: 0.2013, Val Loss: 27.1561, Val Acc: 0.1647\n",
      "Epoch 26/50, Train Loss: 123.8973, Train Acc: 0.2008, Val Loss: 27.2096, Val Acc: 0.1926\n",
      "Epoch 27/50, Train Loss: 123.7231, Train Acc: 0.1988, Val Loss: 27.1524, Val Acc: 0.1647\n",
      "Epoch 28/50, Train Loss: 123.8498, Train Acc: 0.2142, Val Loss: 27.1595, Val Acc: 0.1763\n",
      "Epoch 29/50, Train Loss: 123.2962, Train Acc: 0.2058, Val Loss: 27.1422, Val Acc: 0.1647\n",
      "Epoch 30/50, Train Loss: 123.6003, Train Acc: 0.2127, Val Loss: 27.1499, Val Acc: 0.1647\n",
      "Epoch 31/50, Train Loss: 123.6399, Train Acc: 0.2038, Val Loss: 27.1449, Val Acc: 0.1647\n",
      "Epoch 32/50, Train Loss: 123.8762, Train Acc: 0.2083, Val Loss: 27.1417, Val Acc: 0.1647\n",
      "Epoch 33/50, Train Loss: 123.8129, Train Acc: 0.2157, Val Loss: 27.1407, Val Acc: 0.1624\n"
     ]
    }
   ],
   "source": [
    "writer = SummaryWriter(\"runs/emotion_classifier\")\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        y_batch = y_batch.argmax(dim=1)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(X_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        correct += predicted.eq(y_batch).sum().item()\n",
    "        total += y_batch.size(0)\n",
    "    \n",
    "    train_acc = correct / total\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in val_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            y_batch = y_batch.argmax(dim=1)\n",
    "            \n",
    "            outputs = model(X_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            correct += predicted.eq(y_batch).sum().item()\n",
    "            total += y_batch.size(0)\n",
    "    \n",
    "    val_acc = correct / total\n",
    "\n",
    "    writer.add_scalar(\"Loss/Train\", train_loss, epoch)\n",
    "    writer.add_scalar(\"Loss/Validation\", val_loss, epoch)\n",
    "    writer.add_scalar(\"Accuracy/Train\", train_acc, epoch)\n",
    "    writer.add_scalar(\"Accuracy/Validation\", val_acc, epoch)\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{EPOCHS}, Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, \"\n",
    "          f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "    \n",
    "writer.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eval model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0614, Test Accuracy: 0.2245\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "test_loss = 0\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in DataLoader(TensorDataset(X_test, y_test), batch_size=BATCH_SIZE, shuffle=False):\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        \n",
    "        y_batch = y_batch.argmax(dim=1)\n",
    "        \n",
    "        outputs = model(X_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        \n",
    "        test_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        correct += predicted.eq(y_batch).sum().item()\n",
    "        total += y_batch.size(0)\n",
    "\n",
    "test_loss /= len(y_test)\n",
    "test_acc = correct / total\n",
    "\n",
    "print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_acc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
