{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.abspath('..'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.5.1+cu118\n",
      "**********\n",
      "_CUDA version: \n",
      "CUDA version:\n",
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2024 NVIDIA Corporation\n",
      "Built on Wed_Oct_30_01:18:48_Pacific_Daylight_Time_2024\n",
      "Cuda compilation tools, release 12.6, V12.6.85\n",
      "Build cuda_12.6.r12.6/compiler.35059454_0\n",
      "\n",
      "**********\n",
      "CUDNN version: 90100\n",
      "Available GPU devices: 1\n",
      "Device Name: NVIDIA GeForce RTX 4070 Ti SUPER\n"
     ]
    }
   ],
   "source": [
    "from utils import get_cuda_info\n",
    "\n",
    "get_cuda_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zdobycie danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import load_data, convert_landmarks_to_eye_movements\n",
    "\n",
    "all_data, all_labels = load_data('silesian_deception')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "converted_data, blinks = convert_landmarks_to_eye_movements(all_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ograniczenie do pierwszych N klatek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "blinks = np.array([d[:1000] for d in blinks], dtype=object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import preprocess_data\n",
    "\n",
    "X_train, X_val, X_test, y_train, y_val, y_test = preprocess_data(blinks, all_labels, binarize_labels=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([700, 1000])\n",
      "torch.Size([700])\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> Class distribution <===\n",
      "0: 301\n",
      "1: 699\n",
      "=============><=============\n"
     ]
    }
   ],
   "source": [
    "from utils import get_class_distribution\n",
    "\n",
    "get_class_distribution(all_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL TORCH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zbudowanie modelu ekstrakcji cech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BlinkingTransformerClassifier(nn.Module):\n",
    "    def __init__(self, d_model=64, num_heads=4, num_layers=2):\n",
    "        super().__init__()\n",
    "        self.input_proj = nn.Linear(1, d_model)  # 1 feature: blink signal\n",
    "\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=num_heads, dropout=0.1)\n",
    "        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(d_model, 1)  # binary output\n",
    "        )\n",
    "\n",
    "    def forward(self, x):  # x shape: [batch, time]\n",
    "        x = x.unsqueeze(-1)         # -> [batch, time, 1]\n",
    "        x = self.input_proj(x)      # -> [batch, time, d_model]\n",
    "        x = x.permute(1, 0, 2)      # -> [time, batch, d_model] for Transformer\n",
    "        x = self.encoder(x)         # -> [time, batch, d_model]\n",
    "        x = x.mean(dim=0)           # average over time: [batch, d_model]\n",
    "        out = self.classifier(x)    # -> [batch, 1]\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bartosz\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from torch.optim import Adam\n",
    "\n",
    "model = BlinkingTransformerClassifier()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "pos_weight = torch.tensor([(len(y_train) - y_train.sum()) / y_train.sum()]).to(device)\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "optimizer = Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trening modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "RUNS_FOLDER_PATH = os.path.abspath('runs')\n",
    "writer_path = os.path.join('runs', model.__class__.__qualname__, 'blinking')\n",
    "writer = SummaryWriter(writer_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-1, 0], but got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_functions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_torch_model_binary\n\u001b[1;32m----> 3\u001b[0m \u001b[43mtrain_torch_model_binary\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwriter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwriter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munbalanced\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_prediction_stats\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Bartosz\\Desktop\\automatic-lie-detection\\models\\utils\\model_functions\\train_model.py:134\u001b[0m, in \u001b[0;36mtrain_torch_model_binary\u001b[1;34m(model, criterion, optimizer, X_train, y_train, X_val, y_val, unbalanced, writer, batch_size, epochs, prediction_threshold, show_prediction_stats, lr_scheduler)\u001b[0m\n\u001b[0;32m    131\u001b[0m X_batch, y_batch \u001b[38;5;241m=\u001b[39m X_batch\u001b[38;5;241m.\u001b[39mto(device), y_batch\u001b[38;5;241m.\u001b[39mto(device)\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[0;32m    133\u001b[0m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[1;32m--> 134\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_batch\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m show_prediction_stats:\n\u001b[0;32m    136\u001b[0m     probs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msigmoid(outputs)\u001b[38;5;241m.\u001b[39mdetach()\n",
      "\u001b[1;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-1, 0], but got 1)"
     ]
    }
   ],
   "source": [
    "from utils.model_functions import train_torch_model_binary\n",
    "\n",
    "train_torch_model_binary(model, criterion, optimizer, X_train, y_train, X_val, y_val, writer=writer, batch_size=128, unbalanced=True, show_prediction_stats=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ewaluacja modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================================================================\n",
      "                                          EPOCH STATISTICS                                          \n",
      "====================================================================================================\n",
      "Epoch       : 1\n",
      "----------------------------------------------------------------------------------------------------\n",
      "                                             VALIDATION                                             \n",
      "----------------------------------------------------------------------------------------------------\n",
      "Loss        : 1.3861\n",
      "Accuracy    : 0.5208\n",
      "Precision   : 0.2604\n",
      "Recall      : 0.5000\n",
      "F1 Score    : 0.3425\n",
      "----------------------------------------------------------------------------------------------------\n",
      "                                          VALIDATION EXTRA                                          \n",
      "TP Rate     : 1.0000                                    FP Rate     : 1.0000\n",
      "====================================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from utils.model_functions import eval_torch_model_binary\n",
    "\n",
    "eval_torch_model_binary(model, criterion, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODYNET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Przygotowanie danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_np = X_train.numpy()\n",
    "X_val_np = X_val.numpy()\n",
    "X_test_np = X_test.numpy()\n",
    "y_train_np = y_train.numpy()\n",
    "y_val_np = y_val.numpy()\n",
    "y_test_np = y_test.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "TodyNet_DATA_PATH = os.path.join(\"..\", \"..\", \"src\", \"external\", \"TodyNet\", \"data\", \"UCR\", \"MIAMI_DECEPTION_EYE_MOVEMENT\")\n",
    "\n",
    "os.makedirs(TodyNet_DATA_PATH, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tensor = torch.tensor(X_train_np, dtype=torch.float32).unsqueeze(1)  # adding channel dimension\n",
    "X_val_tensor = torch.tensor(X_val_np, dtype=torch.float32).unsqueeze(1)\n",
    "X_test_tensor = torch.tensor(X_test_np, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "# Save the data in PyTorch (.pt) format\n",
    "torch.save(X_train_tensor, os.path.join(TodyNet_DATA_PATH, 'X_train.pt'))\n",
    "torch.save(X_val_tensor, os.path.join(TodyNet_DATA_PATH, 'X_valid.pt'))\n",
    "torch.save(X_test_tensor, os.path.join(TodyNet_DATA_PATH, 'X.pt'))\n",
    "\n",
    "# Save the labels in PyTorch (.pt) format\n",
    "torch.save(y_train, os.path.join(TodyNet_DATA_PATH, 'y_train.pt'))\n",
    "torch.save(y_val, os.path.join(TodyNet_DATA_PATH, 'y_valid.pt'))\n",
    "torch.save(y_test, os.path.join(TodyNet_DATA_PATH, 'y.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([224, 1, 1679, 2])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tensor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trening modelu [pool_ratio 0.8, ponieważ rozmiar danych jest zbyt duży na 0.2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cd .\\src\\external\\TodyNet\\src\\ & python train.py --dataset='MIAMI_DECEPTION_EYE_MOVEMENT' --num_layers 1 --in_dim 16 --hidden_dim 16 --out_dim 16 --pool_ratio 0.0 --kern_size \"3\" --groups 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
